# How LLM Generates Reconciliation Rules - Simple Explanation

## ğŸ¯ The Big Picture

The system generates reconciliation rules in **TWO WAYS**:

1. **Pattern-Based Rules** (Simple, Fast) âœ…
2. **LLM-Based Rules** (Smart, Semantic) ğŸ¤–

---

## ğŸ“Š Step-by-Step Process

### Step 1: Load Schemas
```
Input: Schema names (e.g., "orderMgmt-catalog", "qinspect-designcode")
â†“
Output: Schema information (tables, columns, data types)
```

### Step 2: Query Knowledge Graph
```
Input: Knowledge graph name
â†“
Output: Relationships between entities (e.g., "catalog.id relates to design_code_master.id")
```

### Step 3: Generate Pattern-Based Rules (Always Done)
```
Logic: Look for matching column names
Example:
  - If both schemas have "id" column â†’ Create rule: match on id
  - If both schemas have "code" column â†’ Create rule: match on code
  - If both schemas have "name" column â†’ Create rule: match on name

Output: Basic rules with 0.75 confidence
```

### Step 4: Generate LLM-Based Rules (If Enabled)
```
IF use_llm = true:
  â†“
  1. Prepare prompt with:
     - All schemas information
     - All relationships from KG
     - Instructions for rule generation
  â†“
  2. Send to OpenAI GPT-3.5-turbo (or GPT-4)
  â†“
  3. GPT analyzes and suggests:
     - Matching columns
     - Match strategies (exact, fuzzy, semantic)
     - Confidence scores
     - Transformation logic if needed
  â†“
  4. Parse GPT response and create rules
  â†“
  Output: Smart semantic rules
```

### Step 5: Combine & Filter
```
All Rules = Pattern-Based Rules + LLM Rules
â†“
Filter: Keep only rules with confidence â‰¥ min_confidence (default 0.7)
â†“
Remove: Duplicate rules
â†“
Output: Final ruleset
```

---

## ğŸ¤– What Does GPT Do?

### System Prompt (Role)
```
"You are an expert data integration specialist. 
Generate reconciliation rules for matching data across 
different database schemas."
```

### User Prompt (Task)
```
Given these schemas and relationships, generate rules that:
1. Identify matching columns across schemas
2. Suggest match strategies (exact, fuzzy, composite)
3. Provide SQL/Python transformation logic if needed
4. Score confidence for each rule

SCHEMAS:
{
  "orderMgmt-catalog": {
    "tables": {
      "catalog": {
        "columns": ["id", "code", "name", "category"]
      }
    }
  },
  "qinspect-designcode": {
    "tables": {
      "design_code_master": {
        "columns": ["id", "code", "design_name", "category_id"]
      }
    }
  }
}

RELATIONSHIPS:
[
  {
    "source_table": "catalog",
    "target_table": "design_code_master",
    "confidence": 0.85,
    "reasoning": "Both contain product information"
  }
]
```

### GPT Response (Example)
```json
{
  "rules": [
    {
      "rule_name": "Match_by_ID",
      "source_table": "catalog",
      "source_columns": ["id"],
      "target_table": "design_code_master",
      "target_columns": ["id"],
      "match_type": "exact",
      "confidence": 0.95,
      "reasoning": "Both have primary key 'id' with same data type"
    },
    {
      "rule_name": "Match_by_Code",
      "source_table": "catalog",
      "source_columns": ["code"],
      "target_table": "design_code_master",
      "target_columns": ["code"],
      "match_type": "exact",
      "confidence": 0.90,
      "reasoning": "Both have product code column"
    },
    {
      "rule_name": "Match_by_Name_Semantic",
      "source_table": "catalog",
      "source_columns": ["name"],
      "target_table": "design_code_master",
      "target_columns": ["design_name"],
      "match_type": "semantic",
      "confidence": 0.80,
      "reasoning": "Column names suggest product name matching"
    }
  ]
}
```

---

## ğŸ“‹ Generated Rule Structure

Each rule contains:

```json
{
  "rule_id": "RULE_ABC123",
  "rule_name": "Match_by_ID",
  "source_schema": "ordermgmt",
  "source_table": "catalog",
  "source_columns": ["id"],
  "target_schema": "newamazon",
  "target_table": "design_code_master",
  "target_columns": ["id"],
  "match_type": "exact",           // exact, fuzzy, semantic, pattern
  "transformation": null,           // SQL/Python if needed
  "confidence_score": 0.95,         // 0.0 to 1.0
  "reasoning": "Both have primary key 'id'",
  "validation_status": "LIKELY",    // VALID, LIKELY, UNCERTAIN
  "llm_generated": true,            // true if from LLM, false if pattern-based
  "created_at": "2025-10-24T..."
}
```

---

## ğŸ”„ Complete Workflow

```
User Request: Generate Rules
    â†“
Load Schemas (orderMgmt-catalog, qinspect-designcode)
    â†“
Query Knowledge Graph for relationships
    â†“
Generate Pattern-Based Rules
    â”œâ”€ Rule 1: Match on "id" (confidence: 0.75)
    â”œâ”€ Rule 2: Match on "code" (confidence: 0.75)
    â””â”€ Rule 3: Match on "name" (confidence: 0.75)
    â†“
Generate LLM-Based Rules (if enabled)
    â”œâ”€ Call OpenAI GPT-3.5-turbo
    â”œâ”€ Send schemas + relationships
    â”œâ”€ GPT analyzes and suggests rules
    â””â”€ Parse response
    â†“
Combine Rules
    â”œâ”€ Pattern-Based: 3 rules
    â”œâ”€ LLM-Based: 5 rules
    â””â”€ Total: 8 rules
    â†“
Filter by Confidence (â‰¥ 0.7)
    â””â”€ All 8 rules pass
    â†“
Remove Duplicates
    â””â”€ Final: 8 unique rules
    â†“
Create Ruleset
    â”œâ”€ Ruleset ID: RECON_07C55A55
    â”œâ”€ Total Rules: 8
    â”œâ”€ Pattern-Based: 3
    â””â”€ LLM-Based: 5
    â†“
Save to MongoDB & File System
    â†“
Return to User
```

---

## âš™ï¸ Configuration

### Enable/Disable LLM
```python
# In .env file
OPENAI_API_KEY=sk-...              # Your OpenAI API key
OPENAI_MODEL=gpt-3.5-turbo         # Model to use
OPENAI_TEMPERATURE=0.7             # Creativity (0=deterministic, 1=creative)
OPENAI_MAX_TOKENS=2000             # Max response length
ENABLE_LLM_EXTRACTION=true         # Enable LLM features
```

### If LLM is Disabled
```
- Only pattern-based rules are generated
- Faster execution
- Lower cost (no API calls)
- Less intelligent matching
```

---

## ğŸ“Š Current Project Status

**In Your Project:**
- âœ… Pattern-based rules: **WORKING** (19 rules generated)
- âš ï¸ LLM-based rules: **DISABLED** (OPENAI_API_KEY not set)

**To Enable LLM:**
1. Get OpenAI API key from https://platform.openai.com/api-keys
2. Add to `.env` file: `OPENAI_API_KEY=sk-...`
3. Restart the application
4. Re-run rule generation

---

## ğŸ¯ Key Takeaways

| Aspect | Pattern-Based | LLM-Based |
|--------|---------------|-----------|
| **Speed** | Fast âš¡ | Slower (API call) ğŸŒ |
| **Cost** | Free | Costs money ğŸ’° |
| **Intelligence** | Simple matching | Semantic understanding ğŸ§  |
| **Accuracy** | Good for exact matches | Better for fuzzy/semantic |
| **Confidence** | 0.75 (fixed) | Variable (0.7-0.95) |

---

**Version**: 1.0  
**Date**: 2025-10-24  
**Status**: âœ… Complete

